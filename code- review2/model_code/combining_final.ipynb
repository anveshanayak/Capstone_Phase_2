{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# def preprocess_dicra_files(df, file_path):\n",
    "#     # Extract the prefix from the file name\n",
    "#     file_name = os.path.basename(file_path)  # Get the file name from the path\n",
    "#     prefix = file_name.split('_')[0]  # Extract prefix before the first '_'\n",
    "\n",
    "#     # Check if 'source_file' column exists\n",
    "#     if 'source_file' not in df.columns:\n",
    "#         raise KeyError(\"'source_file' column not found in DataFrame\")\n",
    "\n",
    "#     # Modify the DataFrame\n",
    "#     df['date'] = pd.to_datetime(df['source_file'].str.replace('.geojson', '', regex=False), format='%d-%m-%Y', errors='coerce')\n",
    "    \n",
    "#     # Convert the date to dd-mm-yyyy format\n",
    "    \n",
    "\n",
    "#     # Drop the original 'source_file' column\n",
    "#     df = df.drop(columns=['source_file'])\n",
    "\n",
    "#     # Rename the column to match other data\n",
    "#     if 'district_name' in df.columns:\n",
    "#         df = df.rename(columns={'district_name': 'district'})\n",
    "#     else:\n",
    "#         raise KeyError(\"'district_name' column not found in DataFrame\")\n",
    "    \n",
    "#     # Rename columns to include prefix\n",
    "#     new_column_names = {}\n",
    "#     for col in ['min', 'max', 'mean', 'count', 'sum', 'median']:\n",
    "#         if col in df.columns:\n",
    "#             new_column_names[col] = f'{prefix}_{col}'\n",
    "#     df = df.rename(columns=new_column_names)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def process_and_merge_files(file_paths):\n",
    "#     dfs = []\n",
    "#     for file_path in file_paths:\n",
    "#         try:\n",
    "#             df = pd.read_csv(file_path)\n",
    "#             processed_df = preprocess_dicra_files(df, file_path)\n",
    "#             dfs.append(processed_df)\n",
    "#         except KeyError as e:\n",
    "#             print(f\"KeyError: {e} in file {file_path}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Exception: {e} in file {file_path}\")\n",
    "\n",
    "#     if dfs:\n",
    "#         # Initialize with the first DataFrame\n",
    "#         combined_df = dfs[0]\n",
    "        \n",
    "#         # Merge each subsequent DataFrame on 'date' and 'district' with suffixes\n",
    "#         for df in dfs[1:]:\n",
    "#             combined_df = pd.merge(combined_df, df, on=['date', 'district'], how='outer', suffixes=('', '_dup'))\n",
    "        \n",
    "#         # Optionally, drop duplicate columns if needed\n",
    "#         combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "        \n",
    "#         # if column name contains _dup drop it\n",
    "#         # TO DO\n",
    "#         return combined_df\n",
    "#     else:\n",
    "#         print(\"No data processed.\")\n",
    "#         return None\n",
    "\n",
    "# # Define file paths\n",
    "# files_2022 = [\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\LST_2022.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\NO2_2022.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PM25_2022.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PRECIPITATION_2022.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\SSM_2022.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\TEMPERATURE_2022.csv'\n",
    "# ]\n",
    "\n",
    "# files_2023 = [\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\LST_2023.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\NO2_2023.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PM25_2023.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PRECIPITATION_2023.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\SSM_2023.csv',\n",
    "#     'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\TEMPERATURE_2023.csv'\n",
    "# ]\n",
    "\n",
    "# # Process and merge files for 2022\n",
    "# df_2022_combined = process_and_merge_files(files_2022)\n",
    "# if df_2022_combined is not None:\n",
    "#     df_2022_combined.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\Combined\\\\DICRA_2022.csv', index=False)\n",
    "\n",
    "# # Process and merge files for 2023\n",
    "# df_2023_combined = process_and_merge_files(files_2023)\n",
    "# if df_2023_combined is not None:\n",
    "#     df_2023_combined.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\Combined\\\\DICRA_2023.csv', index=False)\n",
    "\n",
    "# # # Load and preprocess desagri_yield_data\n",
    "# # desagri_yield_data = pd.read_csv('yield_data.csv')\n",
    "# # desagri_yield_data.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\desagri_yield_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def preprocess_dicra_files(df, file_path):\n",
    "    # Extract the prefix from the file name\n",
    "    file_name = os.path.basename(file_path)  # Get the file name from the path\n",
    "    prefix = file_name.split('_')[0]  # Extract prefix before the first '_'\n",
    "\n",
    "    # Check if 'source_file' column exists\n",
    "    if 'source_file' not in df.columns:\n",
    "        raise KeyError(\"'source_file' column not found in DataFrame\")\n",
    "\n",
    "    # Modify the DataFrame\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df['source_file'].str.replace('.geojson', '', regex=False), \n",
    "        format='%d-%m-%Y', \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Convert the date to month-year (mm-yyyy) format\n",
    "    df['date'] = df['date'].dt.strftime('%m-%Y')\n",
    "\n",
    "    # Drop the original 'source_file' column\n",
    "    df = df.drop(columns=['source_file'])\n",
    "    df = df.drop(columns=['bounds'])\n",
    "\n",
    "    # Rename the column to match other data\n",
    "    if 'district_name' in df.columns:\n",
    "        df = df.rename(columns={'district_name': 'district'})\n",
    "    else:\n",
    "        raise KeyError(\"'district_name' column not found in DataFrame\")\n",
    "    \n",
    "    # Rename columns to include prefix\n",
    "    new_column_names = {}\n",
    "    for col in ['min', 'max', 'mean', 'count', 'sum', 'median']:\n",
    "        if col in df.columns:\n",
    "            new_column_names[col] = f'{prefix}_{col}'\n",
    "    df = df.rename(columns=new_column_names)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_and_merge_files(file_paths):\n",
    "    dfs = []\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            processed_df = preprocess_dicra_files(df, file_path)\n",
    "            dfs.append(processed_df)\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError: {e} in file {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e} in file {file_path}\")\n",
    "\n",
    "    if dfs:\n",
    "        # Initialize with the first DataFrame\n",
    "        combined_df = dfs[0]\n",
    "        \n",
    "        # Merge each subsequent DataFrame on 'date' and 'district' with suffixes\n",
    "        for df in dfs[1:]:\n",
    "            combined_df = pd.merge(combined_df, df, on=['date', 'district'], how='outer', suffixes=('', '_dup'))\n",
    "        \n",
    "        # Optionally, drop duplicate columns if needed\n",
    "        combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "        \n",
    "        # if column name contains _dup drop it\n",
    "        # TO DO\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No data processed.\")\n",
    "        return None\n",
    "\n",
    "# Define file paths\n",
    "files_2022 = [\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\LST_2022.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\NO2_2022.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PM25_2022.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PRECIPITATION_2022.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\SSM_2022.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\TEMPERATURE_2022.csv'\n",
    "]\n",
    "\n",
    "files_2023 = [\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\LST_2023.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\NO2_2023.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PM25_2023.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\PRECIPITATION_2023.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\SSM_2023.csv',\n",
    "    'C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\TEMPERATURE_2023.csv'\n",
    "]\n",
    "\n",
    "# Process and merge files for 2022\n",
    "df_2022_combined = process_and_merge_files(files_2022)\n",
    "if df_2022_combined is not None:\n",
    "    df_2022_combined = df_2022_combined.drop(columns=['area_dup', 'geometry_dup', 'uid_dup','centroid_dup'])\n",
    "    df_2022_combined.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\Combined\\\\DICRA_2022_final.csv', index=False)\n",
    "\n",
    "# Process and merge files for 2023\n",
    "df_2023_combined = process_and_merge_files(files_2023)\n",
    "if df_2023_combined is not None:\n",
    "    df_2023_combined = df_2023_combined.drop(columns=['area_dup', 'geometry_dup', 'uid_dup','centroid_dup'])\n",
    "    df_2023_combined.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\Combined\\\\DICRA_2023_final.csv', index=False)\n",
    "\n",
    "# # Load and preprocess desagri_yield_data\n",
    "# desagri_yield_data = pd.read_csv('yield_data.csv')\n",
    "# desagri_yield_data.to_csv('C:\\\\Anna_Data_D_files\\\\sem6\\\\z_capstone\\\\Agriculture\\\\A_Phase_2\\\\code-review2\\\\preprocessed_files\\\\DICRA\\\\desagri_yield_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
